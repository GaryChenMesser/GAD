from __future__ import print_function, division, absolute_import
from sadit.util import abstract_method
from sadit.util import Find, DataEndException
class Data(object):
    """abstract base class for data. Data class deals with any implementation
    details of the data. it can be a file, a sql data base, and so on, as long
    as it supports the pure virtual methods defined here.
    """
    def get_rows(self, rg=None, rg_type=None):
        """ get a slice of feature

        Parameters
        ---------------
        rg : list of two floats
            is the range for the slice
        rg_type : str,  {'flow', 'time'}
            type for range

        Returns
        --------------
        list of list

        """
        abstract_method()

    def get_where(self, rg=None, rg_type=None):
        abstract_method()

##############################################################
####     For Hard Disk File Generated by fs-simulator   ######
##############################################################
from sadit.util import np
from sadit.util import argsort
from .DataParser import ParseRecords
class PreloadHardDiskFile(Data):
    """ for hard Disk File Generated by fs-simulator"""
    def __init__(self, f_name):
        """ data_order can be flow_first | feature_first
        """
        self.f_name = f_name
        ip = lambda x:tuple(int(v) for v in x.rsplit('.'))
        self.FORMAT = [
                ('start_time', 3, np.float64),
                ('end_time', 4, np.float64),
                ('src_ip', 5, ip),
                ('src_port', 6, np.int16),
                ('dst_ip', 8, ip),
                ('dst_port', 9, np.int16),
                ('protocol', 10, np.str_),
                ('node', 12, np.str_),
                ('duration', 13, np.float64),
                ('flow_size', 14, np.float64),
                ]
        self.fields = zip(*self.FORMAT)[0]
        self.dt = np.dtype([
            ('start_time', np.float64, 1),
            ('end_time', np.float64, 1),
            ('src_ip', np.int8, (4,)),
            ('src_port', np.int16, 1),
            ('dst_ip', np.int16, (4,)),
            ('dst_port', np.int16, 1),
            ('protocol', np.str_, 5),
            ('node', np.str_ , 5),
            ('duration', np.float64, 1),
            ('flow_size', np.float64, 1),
            ])

        self._init()

    def _init(self):
        self.fea_vec = ParseRecords(self.f_name, self.FORMAT)
        self.table = np.array(self.fea_vec, dtype=self.dt)
        self.row_num = self.table.shape[0]

        self.t = np.array([t for t in self.get_rows('start_time')])
        t_idx = np.argsort(self.t)
        self.table = self.table[t_idx]
        self.t = self.t[t_idx]

        self.min_time = min(self.t)
        self.max_time = max(self.t)

    def get_where(self, rg=None, rg_type=None):
        """ get the absolute position of flows records that within the range.

        Find all flows such that its belong to [rg[0], rg[1]). The interval
        is closed in the starting point and open in the ending pont.

        Parameters
        ------------------
        rg : list or tuple or None
            range of the the data. If rg == None, simply return position
            (0, row_num])
        rg_type : {'flow', 'time'}
            specify the type of the range.

        Returns
        -------------------
        sp, ep : ints
            flows with index such that sp <= idx < ed belongs to the range

        NOTES
        ------------------
        This should be a protected method. However, it is called by some
        outside function thus break the interoperability
        """
        # if not rg: return 0, self.flow_num-1
        if not rg: return 0, self.row_num
        if rg_type == 'flow':
            sp, ep = rg
            if sp >= self.row_num: raise DataEndException()
        elif rg_type == 'time':
            sp = Find(self.t, rg[0]+self.min_time)
            ep = Find(self.t, rg[1]+self.min_time)
            # if rg[1] + self.min_time > self.max_time :
                # import pdb;pdb.set_trace()
                # raise Exception('Probably you set wrong range for normal flows? Go to check DETECTOR_DESC')

            assert(sp != -1 and ep != -1)
            if (sp == len(self.t)-1 or ep == len(self.t)-1):
                # import pdb;pdb.set_trace()
                raise DataEndException()
        else:
            raise ValueError('unknow window type')
        return sp, ep

    def get_rows(self, fields=None, rg=None, rg_type=None):
        if fields is None:
            fields = list(self.fields)
            print('fields', fields)
        sp, ep = self.get_where(rg, rg_type)
        return self.table[sp:ep][fields]

##############################################################
####  For Hard Disk File Generated by pcap2netflow tool,######
####  for more information about pcap2netflow, please   ######
####  visit https://bitbucket.org/hbhzwj/pcap2netflow   ######
##############################################################
import re
def get_ip_port(val):
    ip_tmp, port = val.rsplit(':')
    ip = ip_tmp[1:-1]
    return ip, port

def ParseData_pcap2netflow(fileName):
    """
    the input is the filename of the flow file that needs to be parsed.
    the ouput is list of dictionary contains the information for each flow in the data. all these information are strings, users need
    to tranform them by themselves
    """
    flow = []
    # FORMAT = dict(start_time=3, end_time=4, src_ip=5, sc_port=6, octets=13, ) # Defines the FORMAT of the data file
    fid = open(fileName, 'r')
    while True:
        line = fid.readline()
        if not line or not line.startswith('FLOW'):
            break
        if line == '\n': # Ignore Blank Line
            continue
        item = re.split('[ ]', line) #FIXME need to be changed if want to use port information
        f = dict()
        for i in xrange(1, len(item)-1, 2):
            f[item[i]] = item[i+1]
        src_ip, src_port = get_ip_port(f['src'])
        dst_ip, dst_port = get_ip_port(f['dst'])
        f['src_ip'] = src_ip
        f['src_port'] = src_port
        f['dst_ip'] = dst_ip
        f['dst_port'] = dst_port
        f['flow_size'] = f['octets']

        flow.append(f.values())
    fid.close()

    if not flow: raise Exception('Not even a flow is found. Are you specifying the right filename?')

    return flow, f.keys()

# class PreloadHardDiskFile_pcap2netflow(PreloadHardDiskFile):
#     """data with format of pcap2netflow, (softflowd and flowd-reader)
#     """
#     def _init(self):
#         self.fea_vec, self.fea_name = ParseData_pcap2netflow(self.f_name)
#         self.flow_num = len(self.fea_vec)

#     def _get_where(self, rg=None, rg_type=None):
#         if rg_type != 'flow':
#             import sys
#             print("""[Error]: data of pcap2netflow format can only use flow
#             window, please change your window type to 'flow'""")
#             sys.exit()
#         else:
#             super(PreloadHardDiskFile_pcap2netflow, self)._get_where(rg, rg_type)


""" Data File Generated By Flow Exporter tool
"""
def ParseFlowExporterData(f_name):
    """parse the data format generated by FlowExporter.py tool
    """
    # raw = lambda x:x
    # dotted_int = lambda x: tuple(int(v) for v in x.rsplit('.'))
    def ip_str(x):
        if x.upper() == 'BROADCAST':
            return '255.255.255.255'
        elif len(x.rsplit('.')) != 4: # not ip v4
            return '0.0.0.0' # return an arbitracy address
        else:
            return x

    FORMAT = dict(
            start_time = (0, float),
            src_ip = (1, ip_str),
            dst_ip = (2, ip_str),
            protocol = (3, str),
            flow_size = (4, float),
            flow_dur = (5, float),
            )


    fid = open(f_name, 'r')
    record = []
    while True:
        tline = fid.readline()
        if not tline:
            break
        if tline == '\n': # Ignore Blank Line
            continue
        item = tline.rsplit()
        f = [fmter(item[v]) for (v, fmter) in FORMAT.itervalues()]
        record.append(f)

    fid.close()
    return record, FORMAT.keys()

class PreloadHardDiskFile_FlowExporter(PreloadHardDiskFile):
    def _init(self):
        self.fea_vec, self.fea_name = ParseFlowExporterData(self.f_name)
        self.zip_fea_vec = zip(*self.fea_vec)
        self.t = self.zip_fea_vec[self.fea_name.index('start_time')]
        self.min_time = min(self.t)
        self.flow_num = len(self.fea_vec)


##############################################################
####  For simpleweb.org labled dataset, it is stored in ######
####  mysql server.                                     ######
####  visit http://www.simpleweb.org/wiki/Traces for    ######
####  more information (trace 8)                        ######
##############################################################

from sadit.util import mysql
get_sec_msec = lambda x: [int(x), int( (x-int(x)) * 1e3)]

class SQLFile_SperottoIPOM2009(Data):
    """Data File wrapper for SperottoIPOM2009 format. it is store in mysql server, visit
     http://traces.simpleweb.org/traces/netflow/netflow2/dataset_description.txt
    """
    def __init__(self, spec):
        # self.db = _mysql.connect(**spec)
        self.db = mysql.connect(**spec)
        self._init()

    def _init(self):
        # select minimum time
        self.db.query("""SELECT start_time, start_msec FROM flows WHERE (id = 1);""")
        r = self.db.store_result()
        self.min_time_tuple = r.fetch_row()[0]
        self.min_time = float("%s.%s"%self.min_time_tuple)

        self.db.query("""SELECT MAX(id) FROM flows;""")
        r = self.db.store_result()
        self.flow_num = int(r.fetch_row()[0][0])

        self.db.query("""SELECT end_time, end_msec FROM flows WHERE (id = %d);"""%(self.flow_num))
        r = self.db.store_result()

        self.max_time_tuple = r.fetch_row()[0]
        self.max_time = float("%s.%s"%self.max_time_tuple)

    def _get_sql_where(self, rg=None, rg_type=None):
        if rg:
            if rg_type == 'flow':
                SQL_SEN_WHERE = """ WHERE ( (id >= %f) AND (id < %f) )""" %tuple(rg)
                if rg[0] > self.flow_num:
                    raise DataEndException("reach data end")

            elif rg_type == 'time':
                st = get_sec_msec (rg[0] + self.min_time)
                ed = get_sec_msec (rg[1] + self.min_time)
                SQL_SEN_WHERE = """ WHERE ( (start_time > %d) OR ( (start_time = %d) AND (start_msec >= %d)) ) AND
                             ( (end_time < %d) OR ( (end_time = %d) and (end_msec < %d) ) )""" %(st[0], st[0], st[1], ed[0], ed[0], ed[1])

                # print 'rg[0]', rg[0]
                # print 'self.min_time', self.min_time
                # print 'current time, ', rg[0] + self.min_time
                # print 'self.maxtime', self.max_time
                if rg[0] + self.min_time > self.max_time:
                    raise DataEndException("reach data end")
            else:
                print('rg_type', rg_type)
                raise ValueError('unknow window type')
        else:
            SQL_SEN_WHERE = ""
        return SQL_SEN_WHERE

    def get_max(self, fea, rg=None, rg_type=None):
        fea_str = ['MAX(%s)'%(f) for f in fea]
        SQL_SEN = """SELECT %s FROM flows"""%(",".join(fea_str)) + self._get_sql_where(rg, rg_type) + ";"
        self.db.query(SQL_SEN)
        r = self.db.store_result().fetch_row(0)
        return r[0]

    def get_min(self, fea, rg=None, rg_type=None):
        fea_str = ['MIN(%s)'%(f) for f in fea]
        SQL_SEN = """SELECT %s FROM flows"""%(",".join(fea_str)) + self._get_sql_where(rg, rg_type) + ";"
        self.db.query(SQL_SEN)
        r = self.db.store_result().fetch_row(0)
        return r[0]

    def get_fea_slice(self, fea, rg=None, rg_type=None):
        """this function is to get a chunk of feature vector.
        The feature belongs flows within the range specified by **rg**
        **rg_type** can be ['flow' | 'time' ].
        """
        SQL_SEN = """SELECT %s FROM flows"""%(",".join(fea)) + self._get_sql_where(rg, rg_type) + ";"
        # print SQL_SEN
        self.db.query(SQL_SEN)
        result = self.db.store_result().fetch_row(0)
        # return [line[0] for line in result] if len(fea) == 1 else result
        return result


#######################################################
## Flow Records Generated by xflow tools            ###
#######################################################
from time import strptime, mktime
# def argsort(seq):
    # http://stackoverflow.com/questions/3071415/efficient-method-to-calculate-the-rank-vector-of-a-list-in-python
    # return sorted(range(len(seq)), key=seq.__getitem__)

# from sadit.util import argsort

class PreloadHardDiskFile_xflow(PreloadHardDiskFile):
    attr_mapping = { # define the synonym
            'src_ip': 'client_ip',
            'flow_size': 'Cb',
            }

    def _init(self):
        self.fea_vec, self.fea_name = self.parse_xflow(self.f_name)
        self.zip_fea_vec = None
        self.flow_num = len(self.fea_vec)
        self.zip_fea_vec = None
        self.t = [ float(t) for t in self._get_value_list('start_time')]
        self.min_time = min(self.t)
        self.max_time = max(self.t)
        self.flow_num = len(self.t)

    def get_fea_slice(self, fea=None, rg=None, rg_type=None, data_order='flow_first'):
        fea = [self.attr_mapping.get(v, v) for v in fea]# synonym replacement
        return PreloadHardDiskFile.get_fea_slice(self, fea, rg, rg_type, data_order)

    def _get_fea_idx(self, key):
        key = self.attr_mapping.get(key, key)
        return self.fea_name.index(key)

    @staticmethod
    def parse_xflow(fileName):
        """
        the input is the filename of the flow file that needs to be parsed.
        the ouput is list of dictionary contains the information for each flow in the data. all these information are strings, users need
        to tranform them by themselves
        """
        flow = []
        # Defines the FORMAT of the data file
        FORMAT = dict()
        FORMAT[11] = dict(
            start_time=0,
            proto=2,
            client_ip=3,
            direction=4,
            server_ip=5,
            Cb=7,
            Cp=8,
            Sb=9,
            Sp=10,
            )
        FORMAT[12] = dict(
            start_time=0,
            proto=3,
            client_ip=4,
            direction=5,
            server_ip=6,
            Cb=8,
            Cp=9,
            Sb=10,
            Sp=11,
            )
        FORMAT[13] = dict(
            start_time=0,
            proto=2,
            client_ip=3,
            # client_port=4,
            direction=5,
            server_ip=6,
            # server_port=7,
            Cb=9,
            Cp=10,
            Sb=11,
            Sp=12,
            )
        FORMAT[14] = dict(
            start_time=0,
            proto=3,
            client_ip=4,
            # client_port=5,
            direction=6,
            server_ip=7,
            # server_port=8,
            Cb=10,
            Cp=11,
            Sb=12,
            Sp=13,
            )
        # dotted_to_int = lambda x: [int(val) for val in x.rsplit('.')]
        port_str_to_int = lambda x: int(x[1:])
        attr_convert = lambda x: float( x.rsplit('=')[1].rsplit(',')[0] )
        handler = dict(
                start_time = lambda x: mktime(strptime(x, '%Y%m%d.%H:%M:%S')),
                proto = lambda x: x,
                # client_ip = dotted_to_int,
                client_ip = lambda x: x,
                client_port=port_str_to_int,
                direction=lambda x: x,
                # server_ip=dotted_to_int,
                server_ip= lambda x:x,
                server_port=port_str_to_int,
                Cb= attr_convert,
                Cp= attr_convert,
                Sb= attr_convert,
                Sp= lambda x: float(x.rsplit('=')[1].rsplit('\n')[0]),
                )
        fea_name = FORMAT[13].keys()
        fid = open(fileName, 'r')
        t = []
        while True:
            line = fid.readline()
            if not line: break
            item = re.split(' ', line)
            try:
                f = [handler[k](item[v]) for k,v in FORMAT[len(item)].iteritems()]
            except KeyError:
                raise Exception('Unexpected Flow Data Format')
            t.append(f[fea_name.index('start_time')])
            flow.append(f)
        fid.close()

        arg_t = argsort(t)
        sort_flow = [flow[i] for i in arg_t ]

        return sort_flow, fea_name



