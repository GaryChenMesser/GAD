#!/usr/bin/env python
import argparse
import os
parser = argparse.ArgumentParser(description='sadit')
exper_ops = [f_name[:-3] for f_name in os.listdir('./Experiment/') if f_name.lower().endswith('py')]
parser.add_argument('-e', '--experiment', default='None',
        help='specify the experiment name you want to execute. Experiments availiable are: %s. An integrated experiment will run fs-simulator first and use detector to detect the result.'%(exper_ops)
        )

parser.add_argument('-i', '--interpreter', default='python',
        help='--specify the interperter you want to use, now support [cpython], and [pypy](only for detector)')

parser.add_argument('-d', '--detect', default=None,
        help='--detect [filename] will simply detect the flow file, simulator will not run in this case, \
                detector will still use the configuration in the settings.py')

parser.add_argument('-dh', '--data_handler', default=None,
        help="""--specify the data handler you want to use, the availiable
        option is:
        -'fs': process the textexport file of fs simulator
        -'fs_deprec': depreciated handler to process the textexport file of fs simulator
        -'pcap2netflow': process the flow file generated by pcap2netflow tool
        -'SperottoIPOM2009': process the labeled data set provided by simpleweb.org
        -'xflow': process the text export file of ARL xflow tool.
        """)
parser.add_argument('-fo', '--feature_option', default=None,
        help = """ specify the feature option. feature option is a dictionary
        describing the quantization level for each feature. You need at least
        specify 'cluster' and 'dist_to_center'. Note that, the value of 'cluster' is the cluster number. The avaliability of other features depend on the data handler.
        """)

parser.add_argument('-ef', '--export_flows', default=None,
        help = """ specify the file name of exported abnormal flows. Default is not export
        """)
parser.add_argument('-et', '--entropy_threshold', default=None,
        help = """ the threshold for entropy,
        """)
args, res_args = parser.parse_known_args()

# Enter Simple Detect Model
if args.detect:
    from Detector import detect
    import settings
    desc = settings.DETECTOR_DESC
    if args.data_handler: desc['data_handler'] = args.data_handler
    if args.feature_option: desc['fea_option'] = eval(args.feature_option)
    detector = detect(os.path.abspath(args.detect), desc)
    detector.plot_entropy()
    if args.export_flows:
        detector.export_abnormal_flow(args.export_flows,
                entropy_threshold = desc['entropy_threshold'],
                ab_win_portion = desc['ab_win_portion'],
                ab_win_num = desc['ab_win_num'],
                )
    exit()

# Exectue Experiments
try:
    print 'args.experiment', args.experiment
    if args.experiment not in exper_ops:
        raise Exception('invalid experiment')
except:
        parser.print_help()
        exit()

os.chdir('./Experiment/')
# print os.getcwd()
# execfile(args.experiment + '.py')
cmd = args.interpreter + ' ' + args.experiment + '.py ' + ' '.join(res_args)
print '--> ', cmd
os.system(cmd)
os.chdir('..')
